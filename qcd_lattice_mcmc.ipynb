{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa82e2c",
   "metadata": {},
   "source": [
    "# QCD Lattice Field Theory: Monte Carlo Methods\n",
    "\n",
    "This notebook demonstrates the implementation of Monte Carlo methods for lattice field theory, following the approach outlined in \"Quantum Chromodynamics on the Lattice\" and the Creutz article.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We implement and compare:\n",
    "1. **Metropolis algorithm** for Gaussian distribution (as a warmup)\n",
    "2. **1D scalar field theory** using Metropolis algorithm\n",
    "3. **Hybrid Monte Carlo (HMC)** for 1D field theory\n",
    "4. **Comparison** of methods and analysis of autocorrelation times\n",
    "\n",
    "## Theoretical Background\n",
    "\n",
    "### 1D Scalar Field Theory\n",
    "\n",
    "We consider a 1D scalar field $\\phi(x)$ on a lattice with action:\n",
    "\n",
    "$$S[\\phi] = \\sum_{x} \\left[ \\frac{1}{2}(\\phi(x+1) - \\phi(x))^2 + \\frac{1}{2}m^2\\phi(x)^2 + \\lambda\\phi(x)^4 \\right]$$\n",
    "\n",
    "where:\n",
    "- First term: kinetic energy (discrete derivative)\n",
    "- Second term: mass term  \n",
    "- Third term: quartic self-interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f90fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Set up path to src directory\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import our implementations\n",
    "from metropolis import MetropolisGaussian\n",
    "from field_theory_1d import FieldTheory1D\n",
    "from hmc import HMCFieldTheory1D\n",
    "from utils import *\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8072fe",
   "metadata": {},
   "source": [
    "## 1. Metropolis Algorithm for Gaussian Distribution\n",
    "\n",
    "We start with a simple example: sampling from a Gaussian distribution $N(\\mu, \\sigma^2)$ using the Metropolis algorithm.\n",
    "\n",
    "### Algorithm:\n",
    "1. Start with initial configuration $x_0$\n",
    "2. Propose new state: $x' = x + \\delta x$ where $\\delta x \\sim U(-\\epsilon, \\epsilon)$\n",
    "3. Accept with probability: $\\min(1, \\exp(-(S[x'] - S[x])))$\n",
    "4. Repeat\n",
    "\n",
    "For Gaussian: $S[x] = \\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2$ (up to constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ed5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Metropolis sampler for Gaussian distribution\n",
    "sampler = MetropolisGaussian(mu=2.0, sigma=1.5)\n",
    "\n",
    "# Generate samples\n",
    "print(\"Generating samples from Gaussian distribution...\")\n",
    "samples = sampler.sample(n_samples=10000, step_size=1.0, burn_in=1000)\n",
    "\n",
    "# Print diagnostics\n",
    "sampler.print_diagnostics()\n",
    "\n",
    "# Plot results\n",
    "sampler.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a270c5bd",
   "metadata": {},
   "source": [
    "### Effect of Step Size\n",
    "\n",
    "The step size $\\epsilon$ affects the acceptance rate and mixing:\n",
    "- **Too small**: High acceptance, but slow mixing\n",
    "- **Too large**: Low acceptance, inefficient sampling\n",
    "- **Optimal**: ~50% acceptance rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef37ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate step size effect\n",
    "from metropolis import demonstrate_step_size_effect\n",
    "demonstrate_step_size_effect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab838d83",
   "metadata": {},
   "source": [
    "## 2. 1D Field Theory with Metropolis Algorithm\n",
    "\n",
    "Now we implement the Metropolis algorithm for a 1D scalar field theory on a lattice.\n",
    "\n",
    "### Algorithm:\n",
    "1. Start with random field configuration $\\phi(x)$\n",
    "2. **Sweep**: For each lattice site, propose new field value\n",
    "3. Accept/reject based on local action change\n",
    "4. Measure observables after each sweep\n",
    "\n",
    "### Key observables:\n",
    "- $\\langle\\phi\\rangle$: Average field value\n",
    "- $\\langle\\phi^2\\rangle$: Field variance\n",
    "- $\\langle\\phi^4\\rangle$: Fourth moment\n",
    "- Two-point correlation function: $\\langle\\phi(0)\\phi(r)\\rangle$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1D field theory instance\n",
    "field_theory = FieldTheory1D(\n",
    "    lattice_size=50,\n",
    "    mass_squared=0.5,\n",
    "    lambda_coupling=0.1\n",
    ")\n",
    "\n",
    "print(\"Running 1D field theory simulation with Metropolis algorithm...\")\n",
    "\n",
    "# Run simulation\n",
    "results = field_theory.run_simulation(\n",
    "    n_sweeps=10000,\n",
    "    step_size=0.5,\n",
    "    burn_in=2000,\n",
    "    measurement_interval=1\n",
    ")\n",
    "\n",
    "# Analyze results\n",
    "field_theory.analyze_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c6492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot field configuration\n",
    "field_theory.plot_field_configuration()\n",
    "\n",
    "# Plot observables evolution\n",
    "field_theory.plot_observables()\n",
    "\n",
    "# Plot correlation function\n",
    "field_theory.plot_correlation_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c35d1",
   "metadata": {},
   "source": [
    "### Parameter Dependence\n",
    "\n",
    "Let's explore how the field behavior depends on the parameters $m^2$ and $\\lambda$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different parameter settings\n",
    "from field_theory_1d import compare_parameters\n",
    "compare_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c325f8",
   "metadata": {},
   "source": [
    "## 3. Hybrid Monte Carlo (HMC) Implementation\n",
    "\n",
    "HMC combines molecular dynamics with Monte Carlo to achieve better performance, especially for critical slowing down.\n",
    "\n",
    "### Algorithm:\n",
    "1. **Refresh momenta**: $p_i \\sim N(0,1)$ for each site\n",
    "2. **Molecular dynamics**: Evolve $(\\phi, p)$ using Hamilton's equations:\n",
    "   - $\\dot{\\phi}_i = \\frac{\\partial H}{\\partial p_i} = p_i$\n",
    "   - $\\dot{p}_i = -\\frac{\\partial H}{\\partial \\phi_i} = -\\frac{\\partial S}{\\partial \\phi_i}$\n",
    "3. **Metropolis accept/reject**: Based on change in Hamiltonian\n",
    "\n",
    "### Hamiltonian:\n",
    "$$H = \\frac{1}{2}\\sum_i p_i^2 + S[\\phi]$$\n",
    "\n",
    "### Leapfrog Integration:\n",
    "$$p_{n+1/2} = p_n + \\frac{\\epsilon}{2}F_n$$\n",
    "$$\\phi_{n+1} = \\phi_n + \\epsilon p_{n+1/2}$$\n",
    "$$p_{n+1} = p_{n+1/2} + \\frac{\\epsilon}{2}F_{n+1}$$\n",
    "\n",
    "where $F_i = -\\frac{\\partial S}{\\partial \\phi_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HMC field theory instance\n",
    "hmc = HMCFieldTheory1D(\n",
    "    lattice_size=50,\n",
    "    mass_squared=0.5,\n",
    "    lambda_coupling=0.1\n",
    ")\n",
    "\n",
    "print(\"Running 1D field theory simulation with HMC algorithm...\")\n",
    "\n",
    "# Run HMC simulation\n",
    "hmc_results = hmc.run_hmc_simulation(\n",
    "    n_trajectories=2000,\n",
    "    step_size=0.1,\n",
    "    n_md_steps=10,\n",
    "    burn_in=400\n",
    ")\n",
    "\n",
    "# Analyze results\n",
    "hmc.analyze_hmc_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e23cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot HMC diagnostics\n",
    "hmc.plot_hmc_diagnostics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc6c2bd",
   "metadata": {},
   "source": [
    "## 4. Comparison: Metropolis vs HMC\n",
    "\n",
    "Let's compare the performance of Metropolis and HMC algorithms by analyzing their autocorrelation times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69427e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct comparison\n",
    "from hmc import compare_hmc_metropolis\n",
    "compare_hmc_metropolis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8de70",
   "metadata": {},
   "source": [
    "### Detailed Autocorrelation Analysis\n",
    "\n",
    "Let's analyze the autocorrelation properties in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze autocorrelation for both methods\n",
    "metropolis_phi2 = np.array(results['observables']['phi_squared'])\n",
    "hmc_phi2 = np.array(hmc_results['observables']['phi_squared'])\n",
    "\n",
    "# Compute autocorrelation times\n",
    "tau_metropolis = integrated_autocorrelation_time(metropolis_phi2)\n",
    "tau_hmc = integrated_autocorrelation_time(hmc_phi2)\n",
    "\n",
    "print(f\"Autocorrelation time comparison for ⟨φ²⟩:\")\n",
    "print(f\"Metropolis: {tau_metropolis:.2f}\")\n",
    "print(f\"HMC:        {tau_hmc:.2f}\")\n",
    "print(f\"Improvement factor: {tau_metropolis/tau_hmc:.2f}\")\n",
    "\n",
    "# Effective sample sizes\n",
    "eff_metropolis = effective_sample_size(metropolis_phi2)\n",
    "eff_hmc = effective_sample_size(hmc_phi2)\n",
    "\n",
    "print(f\"\\nEffective sample sizes:\")\n",
    "print(f\"Metropolis: {eff_metropolis:.1f}\")\n",
    "print(f\"HMC:        {eff_hmc:.1f}\")\n",
    "\n",
    "# Plot autocorrelation functions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Metropolis autocorrelation\n",
    "lags_metro, autocorr_metro = autocorrelation_function(metropolis_phi2, max_lag=100)\n",
    "ax1.plot(lags_metro, autocorr_metro, 'b-', label='Metropolis')\n",
    "ax1.axhline(y=1/np.e, color='r', linestyle='--', alpha=0.5, label='1/e')\n",
    "ax1.set_xlabel('Lag')\n",
    "ax1.set_ylabel('Autocorrelation')\n",
    "ax1.set_title('Metropolis Autocorrelation')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# HMC autocorrelation\n",
    "lags_hmc, autocorr_hmc = autocorrelation_function(hmc_phi2, max_lag=100)\n",
    "ax2.plot(lags_hmc, autocorr_hmc, 'g-', label='HMC')\n",
    "ax2.axhline(y=1/np.e, color='r', linestyle='--', alpha=0.5, label='1/e')\n",
    "ax2.set_xlabel('Lag')\n",
    "ax2.set_ylabel('Autocorrelation')\n",
    "ax2.set_title('HMC Autocorrelation')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef1a26",
   "metadata": {},
   "source": [
    "## 5. HMC Parameter Optimization\n",
    "\n",
    "HMC performance depends on:\n",
    "- **Step size** $\\epsilon$: Too small → slow, too large → high rejection\n",
    "- **Number of MD steps** $N$: Determines trajectory length $L = \\epsilon N$\n",
    "- **Trajectory length** $L$: Should be $\\sim 1$ for optimal performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize HMC parameters\n",
    "from hmc import optimize_hmc_parameters\n",
    "optimize_hmc_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb04d45",
   "metadata": {},
   "source": [
    "## 6. Error Analysis\n",
    "\n",
    "Let's perform a proper error analysis using jackknife and bootstrap methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4c6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis for key observables\n",
    "print(\"Error Analysis for ⟨φ²⟩ observable:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Metropolis results\n",
    "metropolis_mean, metropolis_jack_err = jackknife_error(metropolis_phi2)\n",
    "metropolis_boot_mean, metropolis_boot_err = bootstrap_error(metropolis_phi2)\n",
    "\n",
    "print(f\"\\nMetropolis:\")\n",
    "print(f\"  Mean: {metropolis_mean:.6f}\")\n",
    "print(f\"  Jackknife error: {metropolis_jack_err:.6f}\")\n",
    "print(f\"  Bootstrap error: {metropolis_boot_err:.6f}\")\n",
    "\n",
    "# HMC results\n",
    "hmc_mean, hmc_jack_err = jackknife_error(hmc_phi2)\n",
    "hmc_boot_mean, hmc_boot_err = bootstrap_error(hmc_phi2)\n",
    "\n",
    "print(f\"\\nHMC:\")\n",
    "print(f\"  Mean: {hmc_mean:.6f}\")\n",
    "print(f\"  Jackknife error: {hmc_jack_err:.6f}\")\n",
    "print(f\"  Bootstrap error: {hmc_boot_err:.6f}\")\n",
    "\n",
    "# Compare statistical errors\n",
    "print(f\"\\nStatistical error comparison:\")\n",
    "print(f\"  Metropolis / HMC (jackknife): {metropolis_jack_err / hmc_jack_err:.2f}\")\n",
    "print(f\"  Metropolis / HMC (bootstrap): {metropolis_boot_err / hmc_boot_err:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47bb9a1",
   "metadata": {},
   "source": [
    "## 7. Binning Analysis\n",
    "\n",
    "Binning analysis helps estimate the true statistical error by accounting for autocorrelations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861df570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning analysis\n",
    "print(\"Binning Analysis:\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "# Metropolis binning\n",
    "plot_binning_analysis(metropolis_phi2, title=\"Metropolis Binning Analysis\")\n",
    "\n",
    "# HMC binning\n",
    "plot_binning_analysis(hmc_phi2, title=\"HMC Binning Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14aba15",
   "metadata": {},
   "source": [
    "## 8. Summary and Conclusions\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Metropolis Algorithm**: Simple to implement, good for understanding MCMC basics\n",
    "2. **HMC Algorithm**: More complex but significantly better performance for field theory\n",
    "3. **Autocorrelation**: HMC typically shows much lower autocorrelation times\n",
    "4. **Parameter Optimization**: Critical for HMC performance\n",
    "\n",
    "### Performance Comparison:\n",
    "- **Autocorrelation time**: HMC typically 2-10x better than Metropolis\n",
    "- **Effective sample size**: HMC generates more independent samples\n",
    "- **Statistical errors**: HMC achieves better precision for same computational cost\n",
    "\n",
    "### Next Steps:\n",
    "1. Implement critical slowing down studies\n",
    "2. Extend to 2D field theory\n",
    "3. Add gauge fields for full QCD\n",
    "4. Implement advanced algorithms (RHMC, multi-level, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38002383",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FINAL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\n1D Field Theory (N={field_theory.N}, m²={field_theory.m_squared}, λ={field_theory.lambda_coupling})\")\n",
    "print(f\"\\nMetropolis Algorithm:\")\n",
    "print(f\"  Acceptance rate: {results['acceptance_rate']:.3f}\")\n",
    "print(f\"  Autocorrelation time: {tau_metropolis:.2f}\")\n",
    "print(f\"  Effective sample size: {eff_metropolis:.1f}\")\n",
    "print(f\"  Statistical error: {metropolis_jack_err:.6f}\")\n",
    "\n",
    "print(f\"\\nHMC Algorithm:\")\n",
    "print(f\"  Acceptance rate: {hmc_results['acceptance_rate']:.3f}\")\n",
    "print(f\"  Autocorrelation time: {tau_hmc:.2f}\")\n",
    "print(f\"  Effective sample size: {eff_hmc:.1f}\")\n",
    "print(f\"  Statistical error: {hmc_jack_err:.6f}\")\n",
    "\n",
    "print(f\"\\nImprovement Factors (HMC vs Metropolis):\")\n",
    "print(f\"  Autocorrelation time: {tau_metropolis/tau_hmc:.2f}x better\")\n",
    "print(f\"  Effective sample size: {eff_hmc/eff_metropolis:.2f}x better\")\n",
    "print(f\"  Statistical precision: {metropolis_jack_err/hmc_jack_err:.2f}x better\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
